apiVersion: helm.toolkit.fluxcd.io/v2
kind: HelmRelease
metadata:
  name: ollama
  namespace: inf
spec:
  interval: 15m
  chart:
    spec:
      chart: ollama
      version: 8.6.1
      sourceRef:
        kind: HelmRepository
        name: truecharts
        namespace: flux-system
      interval: 15m
  timeout: 5m
  maxHistory: 3
  driftDetection:
    mode: warn
  install:
    createNamespace: true
    remediation:
      retries: 3
  upgrade:
    cleanupOnFail: true
    remediation:
      retries: 3
  uninstall:
    keepHistory: false
  values:
    # Configure Open WebUI with correct port
    ui:
      enabled: true
      workload:
        main:
          podSpec:
            containers:
              main:
                ports:
                  - containerPort: 8080
                    name: http
                env:
                  PORT: "8080"
                probes:
                  liveness:
                    enabled: true
                    type: http
                    path: /
                    port: 8080
                    initialDelaySeconds: 30
                    periodSeconds: 30
                    timeoutSeconds: 5
                    failureThreshold: 3
                  readiness:
                    enabled: true
                    type: http
                    path: /
                    port: 8080
                    initialDelaySeconds: 10
                    periodSeconds: 10
                    timeoutSeconds: 5
                    failureThreshold: 3
                  startup:
                    enabled: true
                    type: http
                    path: /
                    port: 8080
                    initialDelaySeconds: 10
                    periodSeconds: 5
                    failureThreshold: 12
      service:
        main:
          ports:
            http:
              port: 8080
              targetPort: 8080
    
    workload:
      main:
        type: Deployment
        podSpec:
          # runtimeClassName: "intel-gpu"
          containers:
            main:
              env:
                OLLAMA_HOST: "0.0.0.0:11434"
                OLLAMA_ORIGINS: "*"
                OLLAMA_GPU_LAYERS: "1"
                OLLAMA_LLM_LIBRARY: "cpu"
              resources:
                requests:
                  memory: 6Gi
                  gpu.intel.com/i915: 1
                limits:
                  memory: 10Gi
                  gpu.intel.com/i915: 1
              probes:
                liveness:
                  enabled: true
                  type: http
                  path: /api/version
                  port: 11434
                  initialDelaySeconds: 30
                  periodSeconds: 30
                  timeoutSeconds: 10
                  failureThreshold: 3
                readiness:
                  enabled: true
                  type: http
                  path: /api/version
                  port: 11434
                  initialDelaySeconds: 10
                  periodSeconds: 10
                  timeoutSeconds: 5
                  failureThreshold: 3
                startup:
                  enabled: true
                  type: tcp
                  port: 11434
                  initialDelaySeconds: 30
                  periodSeconds: 10
                  failureThreshold: 10

    service:
      main:
        ports:
          main:
            port: 11434
      
      # Disable Open WebUI to avoid port conflicts
      ui:
        enabled: false

    ingress:
      main:
        primary: true
        enabled: true
        ingressClassName: internal
        hosts:
          - host: ollama.${DOMAIN_0}
            paths:
              - path: /
                pathType: Prefix
        integrations:
          traefik:
            enabled: false
          certManager:
            enabled: true
            certificateIssuer: "domain-0-le-prod"
